{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hci_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravabc16/datasciencecoursera/blob/master/hci_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rREutUz2pqrR",
        "colab_type": "code",
        "outputId": "e3e76287-1969-4c84-89c8-ee15da93327a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) #max: 1 gpu, 56 cpu\n",
        "sess = tf.Session(config=config) \n",
        "keras.backend.set_session(sess)\n",
        "\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1B4SdilyBwnAOmbFN8AFGbwYy0iCPwnff' # The shareable link\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('fer2013.csv')  \n",
        "df3 = pd.read_csv('fer2013.csv')\n",
        "\n",
        "#variables\n",
        "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
        "batch_size = 256\n",
        "epochs = 5\n",
        "\n",
        "#read kaggle facial expression recognition challenge dataset (fer2013.csv)\n",
        "#https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "with open(\"fer2013.csv\") as f:\n",
        "    content = f.readlines()\n",
        "\n",
        "lines = np.array(content)\n",
        "\n",
        "num_of_instances = lines.size\n",
        "print(\"number of instances: \",num_of_instances)\n",
        "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n",
        "#initialize trainset and test set\n",
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "\n",
        "#------------------------------\n",
        "#transfer train and test set data\n",
        "for i in range(1,num_of_instances):\n",
        "    try:\n",
        "        emotion, img, usage = lines[i].split(\",\")\n",
        "          \n",
        "        val = img.split(\" \")\n",
        "            \n",
        "        pixels = np.array(val, 'float32')\n",
        "        \n",
        "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
        "    \n",
        "        if 'Training' in usage:\n",
        "            y_train.append(emotion)\n",
        "            x_train.append(pixels)\n",
        "        elif 'PublicTest' in usage:\n",
        "            y_test.append(emotion)\n",
        "            x_test.append(pixels)\n",
        "    except:\n",
        "        print(\"\",end=\"\")\n",
        "\n",
        "#------------------------------\n",
        "#data transformation for train and test sets\n",
        "x_train = np.array(x_train, 'float32')\n",
        "y_train = np.array(y_train, 'float32')\n",
        "x_test = np.array(x_test, 'float32')\n",
        "y_test = np.array(y_test, 'float32')\n",
        "\n",
        "x_train /= 255 #normalize inputs between [0, 1]\n",
        "x_test /= 255\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "#------------------------------\n",
        "#construct CNN structure\n",
        "model = Sequential()\n",
        "\n",
        "#1st convolution layer\n",
        "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "#------------------------------\n",
        "#batch process\n",
        "gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
        "\n",
        "#------------------------------\n",
        "\n",
        "model.compile(loss='categorical_crossentropy'\n",
        "    , optimizer=keras.optimizers.Adam()\n",
        "    , metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#------------------------------\n",
        "\n",
        "fit = True\n",
        "\n",
        "if fit == True:\n",
        "\t#model.fit_generator(x_train, y_train, epochs=epochs) #train for all trainset\n",
        "\tmodel.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs) #train for randomly selected one\n",
        "else:\n",
        "\tmodel.load_weights('facial_expression_model_weights.h5') #load weights\n",
        "\t\n",
        "#------------------------------\n",
        "\"\"\"\n",
        "#overall evaluation\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', 100*score[1])\n",
        "\"\"\"\n",
        "#------------------------------\n",
        "#function for drawing bar chart for emotion preditions\n",
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "    \n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "    \n",
        "    plt.show()\n",
        "#------------------------------\n",
        "\n",
        "monitor_testset_results = False\n",
        "\n",
        "if monitor_testset_results == True:\n",
        "\t#make predictions for test set\n",
        "\tpredictions = model.predict(x_test)\n",
        "\n",
        "\tindex = 0\n",
        "\tfor i in predictions:\n",
        "\t\tif index < 30 and index >= 20:\n",
        "\t\t\t#print(i) #predicted scores\n",
        "\t\t\t#print(y_test[index]) #actual scores\n",
        "\t\t\t\n",
        "\t\t\ttesting_img = np.array(x_test[index], 'float32')\n",
        "\t\t\ttesting_img = testing_img.reshape([48, 48]);\n",
        "\t\t\t\n",
        "\t\t\tplt.gray()\n",
        "\t\t\tplt.imshow(testing_img)\n",
        "\t\t\tplt.show()\n",
        "\t\t\t\n",
        "\t\t\tprint(i)\n",
        "\t\t\t\n",
        "\t\t\temotion_analysis(i)\n",
        "\t\t\tprint(\"----------------------------------------------\")\n",
        "\t\tindex = index + 1\n",
        "\n",
        "#------------------------------\n",
        "#make prediction for custom image out of test set\n",
        "\n",
        "img = image.load_img(\"https://drive.google.com/open?id=1TA9mGFbdcxGnxBvMkhMElTDqAU6ekN_K\", grayscale=True, target_size=(48, 48))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "x /= 255\n",
        "\n",
        "custom = model.predict(x)\n",
        "emotion_analysis(custom[0])\n",
        "\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "\n",
        "plt.gray()\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "#------------------------------\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1B4SdilyBwnAOmbFN8AFGbwYy0iCPwnff\n",
            "number of instances:  35888\n",
            "instance length:  2304\n",
            "28709 train samples\n",
            "3589 test samples\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 18s 71ms/step - loss: 1.8091 - acc: 0.2467\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 1.6207 - acc: 0.3479\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 17s 65ms/step - loss: 1.4258 - acc: 0.4490\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 1.3083 - acc: 0.5000\n",
            "Epoch 5/5\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 1.2120 - acc: 0.5372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1599b4f134da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m#make prediction for custom image out of test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://drive.google.com/open?id=1TA9mGFbdcxGnxBvMkhMElTDqAU6ekN_K\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2411\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://drive.google.com/open?id=1TA9mGFbdcxGnxBvMkhMElTDqAU6ekN_K'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gX2gxGsNsOkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c03e3507-4cd3-448a-e548-58a6b61461e5"
      },
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 13.4MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.9MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.8MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.4MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 3.8MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.0MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.0MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.2MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.2MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.7MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 7.8MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 7.8MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.8MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.8MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 7.8MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 36.6MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.9MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.8MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.8MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.8MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 8.9MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 8.8MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 8.9MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 8.9MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 8.8MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 9.1MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 46.6MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 48.0MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 50.4MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 44.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 44.6MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 49.2MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 48.8MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 48.7MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 10.1MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 10.1MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 10.0MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 10.0MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 10.0MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 10.2MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 10.2MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 10.2MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 10.2MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 10.2MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 52.4MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 50.5MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 51.4MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 53.7MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 9.1MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 8.9MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 8.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 8.8MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 8.8MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 8.7MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 8.7MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 8.8MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 8.8MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 8.8MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 46.0MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 50.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 40.5MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 40.6MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 41.4MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 42.4MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 42.4MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 42.4MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 42.4MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 42.3MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 42.5MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 45.3MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 61.8MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 62.4MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 61.0MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 61.3MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 61.6MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 61.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 62.9MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 63.7MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 64.2MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 57.2MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 56.5MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 57.7MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 58.6MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 56.2MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 56.0MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 56.1MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 56.3MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 56.4MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 56.9MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 64.8MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 62.5MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 60.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.0MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hPoR8fCTpu3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEv8H7Tdp9op",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}